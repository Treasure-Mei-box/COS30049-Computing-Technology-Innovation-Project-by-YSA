{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Singapore Data Cleaning and Processing (2015-2024)\n",
        "\n",
        "This notebook cleans and processes raw Singapore data:\n",
        "- **Pollutants data** (PM10, PM2.5, CO, NO2, SO2, O3, AQI)\n",
        "- **Weather data** (Temperature, Humidity, Wind Speed)\n",
        "- **Air Temperature data** (Daily temperature readings)\n",
        "\n",
        "Cleaned data will be saved to: `data/singapore/clean/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup Paths and Verify Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ pollutants: 10 files found\n",
            "‚úÖ weather: 10 files found\n",
            "‚úÖ air_temperature: 10 files found\n",
            "\n",
            "üìÅ Clean data will be saved to: /Users/sharin/Downloads/COS30049/Assignment/Assignment_2/COS30049-Computing-Technology-Innovation-Project-by-YSA/data/singapore/clean\n"
          ]
        }
      ],
      "source": [
        "# Define base paths\n",
        "base_path = Path(\"/Users/sharin/Downloads/COS30049/Assignment/Assignment_2/COS30049-Computing-Technology-Innovation-Project-by-YSA\")\n",
        "data_path = base_path / \"data\" / \"singapore\"\n",
        "raw_path = data_path / \"raw\"\n",
        "clean_path = data_path / \"clean\"\n",
        "\n",
        "# Create clean directory if it doesn't exist\n",
        "os.makedirs(clean_path, exist_ok=True)\n",
        "\n",
        "# Verify raw data directories exist\n",
        "subdirs = ['pollutants', 'weather', 'air_temperature']\n",
        "for subdir in subdirs:\n",
        "    path = raw_path / subdir\n",
        "    if path.exists():\n",
        "        files = list(path.glob('*.csv'))\n",
        "        print(f\"‚úÖ {subdir}: {len(files)} files found\")\n",
        "    else:\n",
        "        print(f\"‚ùå {subdir}: Directory not found!\")\n",
        "\n",
        "print(f\"\\nüìÅ Clean data will be saved to: {clean_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clean Pollutants Data (2015-2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing pollutants data for 2015...\n",
            "  ‚úì 2015: 365 daily records processed\n",
            "Processing pollutants data for 2016...\n",
            "  ‚úì 2016: 319 daily records processed\n",
            "Processing pollutants data for 2017...\n",
            "  ‚úì 2017: 361 daily records processed\n",
            "Processing pollutants data for 2018...\n",
            "  ‚úì 2018: 365 daily records processed\n",
            "Processing pollutants data for 2019...\n",
            "  ‚úì 2019: 360 daily records processed\n",
            "Processing pollutants data for 2020...\n",
            "  ‚úì 2020: 362 daily records processed\n",
            "Processing pollutants data for 2021...\n",
            "  ‚úì 2021: 353 daily records processed\n",
            "Processing pollutants data for 2022...\n",
            "  ‚úì 2022: 364 daily records processed\n",
            "Processing pollutants data for 2023...\n",
            "  ‚úì 2023: 346 daily records processed\n",
            "Processing pollutants data for 2024...\n",
            "  ‚úì 2024: 366 daily records processed\n",
            "\n",
            "‚úÖ Total pollutants records: 3561\n",
            "Date range: 2015-01-01 00:00:00 to 2024-12-31 00:00:00\n",
            "\n",
            "Sample data:\n",
            "     Country      Region       Date   pm10  pm2_5  carbon_monoxide  \\\n",
            "0  Singapore        East 2015-01-01  19.71  13.62           267.75   \n",
            "1  Singapore       North 2015-01-02  19.71  13.62           267.75   \n",
            "2  Singapore  North-East 2015-01-03  19.71  13.62           267.75   \n",
            "3  Singapore        West 2015-01-04  19.71  13.62           267.75   \n",
            "4  Singapore     Central 2015-01-05  19.71  13.62           267.75   \n",
            "\n",
            "   nitrogen_dioxide  sulphur_dioxide  ozone    AQI  \n",
            "0             21.52            24.75  31.92  53.46  \n",
            "1             21.52            24.75  31.92  53.46  \n",
            "2             21.52            24.75  31.92  53.46  \n",
            "3             21.52            24.75  31.92  53.46  \n",
            "4             21.52            24.75  31.92  53.46  \n",
            "\n",
            "Missing values:\n",
            "Country             0\n",
            "Region              0\n",
            "Date                0\n",
            "pm10                0\n",
            "pm2_5               0\n",
            "carbon_monoxide     0\n",
            "nitrogen_dioxide    0\n",
            "sulphur_dioxide     0\n",
            "ozone               0\n",
            "AQI                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def process_pollutants_data(years):\n",
        "    \"\"\"\n",
        "    Process pollutants data for given years.\n",
        "    Aggregates hourly data to daily averages and handles missing values.\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    \n",
        "    for year in years:\n",
        "        file_path = raw_path / 'pollutants' / f'pollutants_{year}.csv'\n",
        "        \n",
        "        if not file_path.exists():\n",
        "            print(f\"‚ö†Ô∏è  Skipping {year}: File not found\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"Processing pollutants data for {year}...\")\n",
        "        \n",
        "        # Read data in chunks to handle large files\n",
        "        chunks = []\n",
        "        for chunk in pd.read_csv(file_path, chunksize=10000):\n",
        "            # Convert date column to datetime\n",
        "            chunk['date'] = pd.to_datetime(chunk['date'])\n",
        "            \n",
        "            # Check if this is 2015 format (Open-Meteo) or 2016+ format (Singapore API)\n",
        "            if 'pm10' in chunk.columns:\n",
        "                # 2015 format - already has correct column names\n",
        "                daily_chunk = chunk.groupby('date').agg({\n",
        "                    'pm10': 'mean',\n",
        "                    'pm2_5': 'mean',\n",
        "                    'carbon_monoxide': 'mean',\n",
        "                    'nitrogen_dioxide': 'mean',\n",
        "                    'sulphur_dioxide': 'mean',\n",
        "                    'ozone': 'mean',\n",
        "                    'aqi': 'mean'\n",
        "                }).reset_index()\n",
        "            else:\n",
        "                # 2016+ format - map Singapore API columns to standard names\n",
        "                # Rename columns to match 2015 format\n",
        "                chunk = chunk.rename(columns={\n",
        "                    'pm10_twenty_four_hourly': 'pm10',\n",
        "                    'pm25_twenty_four_hourly': 'pm2_5',\n",
        "                    'co_eight_hour_max': 'carbon_monoxide',\n",
        "                    'no2_one_hour_max': 'nitrogen_dioxide',\n",
        "                    'so2_twenty_four_hourly': 'sulphur_dioxide',\n",
        "                    'o3_eight_hour_max': 'ozone',\n",
        "                    'psi_twenty_four_hourly': 'aqi'\n",
        "                })\n",
        "                \n",
        "                # Group by date and calculate daily averages\n",
        "                daily_chunk = chunk.groupby('date').agg({\n",
        "                    'pm10': 'mean',\n",
        "                    'pm2_5': 'mean',\n",
        "                    'carbon_monoxide': 'mean',\n",
        "                    'nitrogen_dioxide': 'mean',\n",
        "                    'sulphur_dioxide': 'mean',\n",
        "                    'ozone': 'mean',\n",
        "                    'aqi': 'mean'\n",
        "                }).reset_index()\n",
        "            \n",
        "            chunks.append(daily_chunk)\n",
        "        \n",
        "        # Combine all chunks for this year\n",
        "        year_data = pd.concat(chunks, ignore_index=True)\n",
        "        \n",
        "        # Group again in case there are duplicate dates from chunking\n",
        "        year_data = year_data.groupby('date').mean().reset_index()\n",
        "        \n",
        "        all_data.append(year_data)\n",
        "        print(f\"  ‚úì {year}: {len(year_data)} daily records processed\")\n",
        "    \n",
        "    # Combine all years\n",
        "    if not all_data:\n",
        "        print(\"‚ùå No pollutants data found!\")\n",
        "        return None\n",
        "    \n",
        "    combined_data = pd.concat(all_data, ignore_index=True)\n",
        "    combined_data = combined_data.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Handle missing values - use method parameter instead of deprecated syntax\n",
        "    pollutant_cols = ['pm10', 'pm2_5', 'carbon_monoxide', 'nitrogen_dioxide', 'sulphur_dioxide', 'ozone', 'aqi']\n",
        "    combined_data[pollutant_cols] = combined_data[pollutant_cols].ffill().bfill().fillna(0)\n",
        "    \n",
        "    # Standardize column names for merging (matching final structure)\n",
        "    combined_data = combined_data.rename(columns={'aqi': 'AQI'})\n",
        "    \n",
        "    # Round all numeric columns to 2 decimal places\n",
        "    numeric_cols = ['pm10', 'pm2_5', 'carbon_monoxide', 'nitrogen_dioxide', 'sulphur_dioxide', 'ozone', 'AQI']\n",
        "    combined_data[numeric_cols] = combined_data[numeric_cols].round(2)\n",
        "    \n",
        "    # Add Country column\n",
        "    combined_data['Country'] = 'Singapore'\n",
        "    \n",
        "    # Assign regions cyclically based on date (to distribute data across 5 regions)\n",
        "    # Singapore regions: Central, East, North, North-East, West\n",
        "    regions = ['Central', 'East', 'North', 'North-East', 'West']\n",
        "    combined_data['Region'] = combined_data['date'].apply(lambda x: regions[x.dayofyear % 5])\n",
        "    \n",
        "    # Rename date column to match final format (after using it for region assignment)\n",
        "    combined_data = combined_data.rename(columns={'date': 'Date'})\n",
        "    \n",
        "    # Reorder columns: Country, Region, Date, then pollutants\n",
        "    cols = ['Country', 'Region', 'Date', 'pm10', 'pm2_5', 'carbon_monoxide', \n",
        "            'nitrogen_dioxide', 'sulphur_dioxide', 'ozone', 'AQI']\n",
        "    combined_data = combined_data[cols]\n",
        "    \n",
        "    return combined_data\n",
        "\n",
        "# Process pollutants data for 2015-2024\n",
        "pollutants_clean = process_pollutants_data(range(2015, 2025))\n",
        "\n",
        "if pollutants_clean is not None:\n",
        "    print(f\"\\n‚úÖ Total pollutants records: {len(pollutants_clean)}\")\n",
        "    print(f\"Date range: {pollutants_clean['Date'].min()} to {pollutants_clean['Date'].max()}\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    print(pollutants_clean.head())\n",
        "    print(f\"\\nMissing values:\")\n",
        "    print(pollutants_clean.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Clean Weather Data (2015-2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing weather data for 2015...\n",
            "  ‚úì 2015: 365 daily records processed\n",
            "Processing weather data for 2016...\n",
            "  ‚úì 2016: 366 daily records processed\n",
            "Processing weather data for 2017...\n",
            "  ‚úì 2017: 365 daily records processed\n",
            "Processing weather data for 2018...\n",
            "  ‚úì 2018: 365 daily records processed\n",
            "Processing weather data for 2019...\n",
            "  ‚úì 2019: 365 daily records processed\n",
            "Processing weather data for 2020...\n",
            "  ‚úì 2020: 366 daily records processed\n",
            "Processing weather data for 2021...\n",
            "  ‚úì 2021: 365 daily records processed\n",
            "Processing weather data for 2022...\n",
            "  ‚úì 2022: 365 daily records processed\n",
            "Processing weather data for 2023...\n",
            "  ‚úì 2023: 365 daily records processed\n",
            "Processing weather data for 2024...\n",
            "  ‚úì 2024: 366 daily records processed\n",
            "\n",
            "‚úÖ Total weather records: 3653\n",
            "Date range: 2015-01-01 00:00:00 to 2024-12-31 00:00:00\n",
            "\n",
            "Sample data:\n",
            "     Country      Region       Date  Temperature  RelativeHumidity  WindSpeed\n",
            "0  Singapore        East 2015-01-01        24.62             88.69      11.65\n",
            "1  Singapore       North 2015-01-02        25.49             78.11      14.05\n",
            "2  Singapore  North-East 2015-01-03        25.88             79.30      13.74\n",
            "3  Singapore        West 2015-01-04        25.80             80.06      12.01\n",
            "4  Singapore     Central 2015-01-05        26.06             82.75       9.49\n",
            "\n",
            "Missing values:\n",
            "Country             0\n",
            "Region              0\n",
            "Date                0\n",
            "Temperature         0\n",
            "RelativeHumidity    0\n",
            "WindSpeed           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def process_weather_data(years):\n",
        "    \"\"\"\n",
        "    Process weather data for given years.\n",
        "    Weather data is already in daily format from the API.\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    \n",
        "    for year in years:\n",
        "        file_path = raw_path / 'weather' / f'weather_{year}.csv'\n",
        "        \n",
        "        if not file_path.exists():\n",
        "            print(f\"‚ö†Ô∏è  Skipping {year}: File not found\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"Processing weather data for {year}...\")\n",
        "        \n",
        "        # Read weather data\n",
        "        year_data = pd.read_csv(file_path)\n",
        "        year_data['date'] = pd.to_datetime(year_data['date'])\n",
        "        \n",
        "        all_data.append(year_data)\n",
        "        print(f\"  ‚úì {year}: {len(year_data)} daily records processed\")\n",
        "    \n",
        "    # Combine all years\n",
        "    if not all_data:\n",
        "        print(\"‚ùå No weather data found!\")\n",
        "        return None\n",
        "    \n",
        "    combined_data = pd.concat(all_data, ignore_index=True)\n",
        "    combined_data = combined_data.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Handle missing values\n",
        "    weather_cols = ['temperature_2m', 'relative_humidity_2m', 'wind_speed_10m']\n",
        "    combined_data[weather_cols] = combined_data[weather_cols].ffill().bfill().fillna(0)\n",
        "    \n",
        "    # Add Country column\n",
        "    combined_data['Country'] = 'Singapore'\n",
        "    \n",
        "    # Assign regions cyclically based on date (to distribute data across 5 regions)\n",
        "    # Singapore regions: Central, East, North, North-East, West\n",
        "    regions = ['Central', 'East', 'North', 'North-East', 'West']\n",
        "    combined_data['Region'] = combined_data['date'].apply(lambda x: regions[x.dayofyear % 5])\n",
        "    \n",
        "    # Standardize column names for merging (matching final structure)\n",
        "    combined_data = combined_data.rename(columns={\n",
        "        'temperature_2m': 'Temperature',\n",
        "        'relative_humidity_2m': 'RelativeHumidity',\n",
        "        'wind_speed_10m': 'WindSpeed',\n",
        "        'date': 'Date'\n",
        "    })\n",
        "    \n",
        "    # Round all numeric columns to 2 decimal places\n",
        "    numeric_cols = ['Temperature', 'RelativeHumidity', 'WindSpeed']\n",
        "    combined_data[numeric_cols] = combined_data[numeric_cols].round(2)\n",
        "    \n",
        "    # Reorder columns: Country, Region, Date, Temperature, RelativeHumidity, WindSpeed\n",
        "    combined_data = combined_data[['Country', 'Region', 'Date', 'Temperature', 'RelativeHumidity', 'WindSpeed']]\n",
        "    \n",
        "    return combined_data\n",
        "\n",
        "# Process weather data for 2015-2024\n",
        "weather_clean = process_weather_data(range(2015, 2025))\n",
        "\n",
        "if weather_clean is not None:\n",
        "    print(f\"\\n‚úÖ Total weather records: {len(weather_clean)}\")\n",
        "    print(f\"Date range: {weather_clean['Date'].min()} to {weather_clean['Date'].max()}\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    print(weather_clean.head())\n",
        "    print(f\"\\nMissing values:\")\n",
        "    print(weather_clean.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Clean Air Temperature Data (2015-2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing air temperature data for 2015...\n",
            "  ‚úì 2015: 365 daily records processed\n",
            "Processing air temperature data for 2016...\n",
            "  ‚úì 2016: 366 daily records processed\n",
            "Processing air temperature data for 2017...\n",
            "  ‚úì 2017: 365 daily records processed\n",
            "Processing air temperature data for 2018...\n",
            "  ‚úì 2018: 365 daily records processed\n",
            "Processing air temperature data for 2019...\n",
            "  ‚úì 2019: 365 daily records processed\n",
            "Processing air temperature data for 2020...\n",
            "  ‚úì 2020: 366 daily records processed\n",
            "Processing air temperature data for 2021...\n",
            "  ‚úì 2021: 365 daily records processed\n",
            "Processing air temperature data for 2022...\n",
            "  ‚úì 2022: 365 daily records processed\n",
            "Processing air temperature data for 2023...\n",
            "  ‚úì 2023: 365 daily records processed\n",
            "Processing air temperature data for 2024...\n",
            "  ‚úì 2024: 366 daily records processed\n",
            "\n",
            "‚úÖ Total air temperature records: 3653\n",
            "Date range: 2015-01-01 00:00:00 to 2024-12-31 00:00:00\n",
            "\n",
            "Sample data:\n",
            "     Country      Region       Date  Temperature reading_type  \\\n",
            "0  Singapore        East 2015-01-01        24.62     DBT 1M F   \n",
            "1  Singapore       North 2015-01-02        25.49     DBT 1M F   \n",
            "2  Singapore  North-East 2015-01-03        25.88     DBT 1M F   \n",
            "3  Singapore        West 2015-01-04        25.80     DBT 1M F   \n",
            "4  Singapore     Central 2015-01-05        26.06     DBT 1M F   \n",
            "\n",
            "         station_name  \n",
            "0  Singapore_National  \n",
            "1  Singapore_National  \n",
            "2  Singapore_National  \n",
            "3  Singapore_National  \n",
            "4  Singapore_National  \n",
            "\n",
            "Missing values:\n",
            "Country         0\n",
            "Region          0\n",
            "Date            0\n",
            "Temperature     0\n",
            "reading_type    0\n",
            "station_name    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def process_temperature_data(years):\n",
        "    \"\"\"\n",
        "    Process air temperature data for given years.\n",
        "    Temperature data is already in daily format from the API.\n",
        "    \"\"\"\n",
        "    all_data = []\n",
        "    \n",
        "    for year in years:\n",
        "        file_path = raw_path / 'air_temperature' / f'airtemp_{year}.csv'\n",
        "        \n",
        "        if not file_path.exists():\n",
        "            print(f\"‚ö†Ô∏è  Skipping {year}: File not found\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"Processing air temperature data for {year}...\")\n",
        "        \n",
        "        # Read temperature data\n",
        "        year_data = pd.read_csv(file_path)\n",
        "        year_data['timestamp'] = pd.to_datetime(year_data['timestamp'])\n",
        "        \n",
        "        # Rename timestamp to date for consistency\n",
        "        year_data = year_data.rename(columns={'timestamp': 'date'})\n",
        "        \n",
        "        all_data.append(year_data)\n",
        "        print(f\"  ‚úì {year}: {len(year_data)} daily records processed\")\n",
        "    \n",
        "    # Combine all years\n",
        "    if not all_data:\n",
        "        print(\"‚ùå No air temperature data found!\")\n",
        "        return None\n",
        "    \n",
        "    combined_data = pd.concat(all_data, ignore_index=True)\n",
        "    combined_data = combined_data.sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    # Handle missing values\n",
        "    combined_data['reading_value'] = combined_data['reading_value'].ffill().bfill().fillna(0)\n",
        "    \n",
        "    # Add Country column\n",
        "    combined_data['Country'] = 'Singapore'\n",
        "    \n",
        "    # Assign regions cyclically based on date (to distribute data across 5 regions)\n",
        "    # Singapore regions: Central, East, North, North-East, West\n",
        "    regions = ['Central', 'East', 'North', 'North-East', 'West']\n",
        "    combined_data['Region'] = combined_data['date'].apply(lambda x: regions[x.dayofyear % 5])\n",
        "    \n",
        "    # Standardize column names for merging (matching final structure)\n",
        "    combined_data = combined_data.rename(columns={\n",
        "        'reading_value': 'Temperature',\n",
        "        'date': 'Date'\n",
        "    })\n",
        "    \n",
        "    # Round temperature to 2 decimal places\n",
        "    combined_data['Temperature'] = combined_data['Temperature'].round(2)\n",
        "    \n",
        "    # Reorder columns: Country, Region, Date, Temperature, reading_type, station_name\n",
        "    combined_data = combined_data[['Country', 'Region', 'Date', 'Temperature', 'reading_type', 'station_name']]\n",
        "    \n",
        "    return combined_data\n",
        "\n",
        "# Process air temperature data for 2015-2024\n",
        "temperature_clean = process_temperature_data(range(2015, 2025))\n",
        "\n",
        "if temperature_clean is not None:\n",
        "    print(f\"\\n‚úÖ Total air temperature records: {len(temperature_clean)}\")\n",
        "    print(f\"Date range: {temperature_clean['Date'].min()} to {temperature_clean['Date'].max()}\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    print(temperature_clean.head())\n",
        "    print(f\"\\nMissing values:\")\n",
        "    print(temperature_clean.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Save Cleaned Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Preview Final Merge Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PREVIEW: Final Merged Data Structure\n",
            "================================================================================\n",
            "\n",
            "Final columns: ['Country', 'Region', 'Date', 'AQI', 'Temperature', 'RelativeHumidity', 'WindSpeed']\n",
            "Total merged records: 3561\n",
            "\n",
            "Sample merged data (first 5 rows):\n",
            "     Country      Region       Date    AQI  Temperature  RelativeHumidity  \\\n",
            "0  Singapore        East 2015-01-01  53.46        24.62             88.69   \n",
            "1  Singapore       North 2015-01-02  53.46        25.49             78.11   \n",
            "2  Singapore  North-East 2015-01-03  53.46        25.88             79.30   \n",
            "3  Singapore        West 2015-01-04  53.46        25.80             80.06   \n",
            "4  Singapore     Central 2015-01-05  53.46        26.06             82.75   \n",
            "\n",
            "   WindSpeed  \n",
            "0      11.65  \n",
            "1      14.05  \n",
            "2      13.74  \n",
            "3      12.01  \n",
            "4       9.49  \n",
            "\n",
            "Data types:\n",
            "Country                     object\n",
            "Region                      object\n",
            "Date                datetime64[ns]\n",
            "AQI                        float64\n",
            "Temperature                float64\n",
            "RelativeHumidity           float64\n",
            "WindSpeed                  float64\n",
            "dtype: object\n",
            "\n",
            "All numeric values are rounded to 2 decimal places ‚úì\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Preview how the final merged data will look\n",
        "if pollutants_clean is not None and weather_clean is not None:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"PREVIEW: Final Merged Data Structure\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Merge pollutants and weather on Date\n",
        "    preview_merge = pd.merge(\n",
        "        pollutants_clean[['Country', 'Region', 'Date', 'AQI']],\n",
        "        weather_clean[['Date', 'Temperature', 'RelativeHumidity', 'WindSpeed']],\n",
        "        on='Date',\n",
        "        how='inner'\n",
        "    )\n",
        "    \n",
        "    # Reorder columns to match final structure\n",
        "    preview_merge = preview_merge[['Country', 'Region', 'Date', 'AQI', 'Temperature', 'RelativeHumidity', 'WindSpeed']]\n",
        "    \n",
        "    print(f\"\\nFinal columns: {list(preview_merge.columns)}\")\n",
        "    print(f\"Total merged records: {len(preview_merge)}\")\n",
        "    print(f\"\\nSample merged data (first 5 rows):\")\n",
        "    print(preview_merge.head())\n",
        "    print(f\"\\nData types:\")\n",
        "    print(preview_merge.dtypes)\n",
        "    print(f\"\\nAll numeric values are rounded to 2 decimal places ‚úì\")\n",
        "    print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Cleaned Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving pollutants data year by year...\n",
            "  ‚úÖ pollutants_clean_2015.csv - 365 records\n",
            "  ‚úÖ pollutants_clean_2016.csv - 319 records\n",
            "  ‚úÖ pollutants_clean_2017.csv - 361 records\n",
            "  ‚úÖ pollutants_clean_2018.csv - 365 records\n",
            "  ‚úÖ pollutants_clean_2019.csv - 360 records\n",
            "  ‚úÖ pollutants_clean_2020.csv - 362 records\n",
            "  ‚úÖ pollutants_clean_2021.csv - 353 records\n",
            "  ‚úÖ pollutants_clean_2022.csv - 364 records\n",
            "  ‚úÖ pollutants_clean_2023.csv - 346 records\n",
            "  ‚úÖ pollutants_clean_2024.csv - 366 records\n",
            "Total pollutants records: 3561\n",
            "\n",
            "Saving weather data year by year...\n",
            "  ‚úÖ weather_clean_2015.csv - 365 records\n",
            "  ‚úÖ weather_clean_2016.csv - 366 records\n",
            "  ‚úÖ weather_clean_2017.csv - 365 records\n",
            "  ‚úÖ weather_clean_2018.csv - 365 records\n",
            "  ‚úÖ weather_clean_2019.csv - 365 records\n",
            "  ‚úÖ weather_clean_2020.csv - 366 records\n",
            "  ‚úÖ weather_clean_2021.csv - 365 records\n",
            "  ‚úÖ weather_clean_2022.csv - 365 records\n",
            "  ‚úÖ weather_clean_2023.csv - 365 records\n",
            "  ‚úÖ weather_clean_2024.csv - 366 records\n",
            "Total weather records: 3653\n",
            "\n",
            "Saving air temperature data year by year...\n",
            "  ‚úÖ air_temperature_clean_2015.csv - 365 records\n",
            "  ‚úÖ air_temperature_clean_2016.csv - 366 records\n",
            "  ‚úÖ air_temperature_clean_2017.csv - 365 records\n",
            "  ‚úÖ air_temperature_clean_2018.csv - 365 records\n",
            "  ‚úÖ air_temperature_clean_2019.csv - 365 records\n",
            "  ‚úÖ air_temperature_clean_2020.csv - 366 records\n",
            "  ‚úÖ air_temperature_clean_2021.csv - 365 records\n",
            "  ‚úÖ air_temperature_clean_2022.csv - 365 records\n",
            "  ‚úÖ air_temperature_clean_2023.csv - 365 records\n",
            "  ‚úÖ air_temperature_clean_2024.csv - 366 records\n",
            "Total air temperature records: 3653\n",
            "\n",
            "============================================================\n",
            "DATA CLEANING COMPLETE!\n",
            "All cleaned files saved to: /Users/sharin/Downloads/COS30049/Assignment/Assignment_2/COS30049-Computing-Technology-Innovation-Project-by-YSA/data/singapore/clean\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Save cleaned pollutants data (year by year)\n",
        "if pollutants_clean is not None:\n",
        "    print(\"Saving pollutants data year by year...\")\n",
        "    for year in range(2015, 2025):\n",
        "        year_data = pollutants_clean[pollutants_clean['Date'].dt.year == year]\n",
        "        if len(year_data) > 0:\n",
        "            pollutants_output = clean_path / f'pollutants_clean_{year}.csv'\n",
        "            year_data.to_csv(pollutants_output, index=False)\n",
        "            print(f\"  ‚úÖ pollutants_clean_{year}.csv - {len(year_data)} records\")\n",
        "    print(f\"Total pollutants records: {len(pollutants_clean)}\")\n",
        "\n",
        "# Save cleaned weather data (year by year)\n",
        "if weather_clean is not None:\n",
        "    print(\"\\nSaving weather data year by year...\")\n",
        "    for year in range(2015, 2025):\n",
        "        year_data = weather_clean[weather_clean['Date'].dt.year == year]\n",
        "        if len(year_data) > 0:\n",
        "            weather_output = clean_path / f'weather_clean_{year}.csv'\n",
        "            year_data.to_csv(weather_output, index=False)\n",
        "            print(f\"  ‚úÖ weather_clean_{year}.csv - {len(year_data)} records\")\n",
        "    print(f\"Total weather records: {len(weather_clean)}\")\n",
        "\n",
        "# Save cleaned air temperature data (year by year)\n",
        "if temperature_clean is not None:\n",
        "    print(\"\\nSaving air temperature data year by year...\")\n",
        "    for year in range(2015, 2025):\n",
        "        year_data = temperature_clean[temperature_clean['Date'].dt.year == year]\n",
        "        if len(year_data) > 0:\n",
        "            temperature_output = clean_path / f'air_temperature_clean_{year}.csv'\n",
        "            year_data.to_csv(temperature_output, index=False)\n",
        "            print(f\"  ‚úÖ air_temperature_clean_{year}.csv - {len(year_data)} records\")\n",
        "    print(f\"Total air temperature records: {len(temperature_clean)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA CLEANING COMPLETE!\")\n",
        "print(f\"All cleaned files saved to: {clean_path}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook processed raw Singapore data (2015-2024) and saved cleaned files with **standardized formats** for easy merging.\n",
        "\n",
        "### Output Files (Saved Year by Year):\n",
        "1. **Pollutants: `pollutants_clean_2015.csv` through `pollutants_clean_2024.csv`** (10 files)\n",
        "   - Columns: `Country`, `Region`, `Date`, `pm10`, `pm2_5`, `carbon_monoxide`, `nitrogen_dioxide`, `sulphur_dioxide`, `ozone`, `AQI`\n",
        "   - All values rounded to 2 decimal places\n",
        "\n",
        "2. **Weather: `weather_clean_2015.csv` through `weather_clean_2024.csv`** (10 files)\n",
        "   - Columns: `Country`, `Region`, `Date`, `Temperature`, `RelativeHumidity`, `WindSpeed`\n",
        "   - All values rounded to 2 decimal places\n",
        "\n",
        "3. **Air Temperature: `air_temperature_clean_2015.csv` through `air_temperature_clean_2024.csv`** (10 files)\n",
        "   - Columns: `Country`, `Region`, `Date`, `Temperature`, `reading_type`, `station_name`\n",
        "   - Temperature values rounded to 2 decimal places\n",
        "\n",
        "### Standardized Format for Merging:\n",
        "All cleaned files now follow a consistent structure:\n",
        "- **Country**: Singapore\n",
        "- **Region**: Central, East, North, North-East, or West (distributed cyclically)\n",
        "- **Date**: YYYY-MM-DD format\n",
        "- **All numeric values**: Rounded to 2 decimal places\n",
        "\n",
        "### Final Merged Structure:\n",
        "When merging pollutants and weather data, the result will be:\n",
        "```\n",
        "Country | Region | Date | AQI | Temperature | RelativeHumidity | WindSpeed\n",
        "```\n",
        "\n",
        "### Data Processing Steps:\n",
        "- ‚úÖ Loaded raw data from 2015-2024\n",
        "- ‚úÖ Aggregated hourly data to daily averages (for pollutants)\n",
        "- ‚úÖ Handled missing values using forward fill ‚Üí backward fill ‚Üí zero fill\n",
        "- ‚úÖ Standardized column names (Country, Region, Date, Temperature, RelativeHumidity, WindSpeed, AQI)\n",
        "- ‚úÖ Rounded all numeric values to 2 decimal places\n",
        "- ‚úÖ Added Country and Region columns for consistency\n",
        "- ‚úÖ Saved cleaned data to `data/singapore/clean/` directory\n",
        "\n",
        "### Next Steps:\n",
        "1. Use `pollutants_clean.csv` and `weather_clean.csv` for final merging\n",
        "2. Simple merge on `Date` column will create the final dataset\n",
        "3. Data is ready for visualization and modeling"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
