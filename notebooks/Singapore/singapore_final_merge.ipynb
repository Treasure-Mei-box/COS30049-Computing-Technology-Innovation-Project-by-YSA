{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Singapore Final Data Merge (2015-2024)\n",
        "\n",
        "This notebook merges cleaned pollutants and weather data into the final format:\n",
        "- **Columns**: Country | Region | Date | AQI | Temperature | RelativeHumidity | WindSpeed\n",
        "- **Output**: Single merged file saved to `data/singapore/singapore_merged_2015_2024.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Clean data location: /Users/sharin/Downloads/COS30049/Assignment/Assignment_2/COS30049-Computing-Technology-Innovation-Project-by-YSA/data/singapore/clean\n",
            "üìÅ Output will be saved to: /Users/sharin/Downloads/COS30049/Assignment/Assignment_2/COS30049-Computing-Technology-Innovation-Project-by-YSA/data/singapore\n"
          ]
        }
      ],
      "source": [
        "# Define base paths\n",
        "base_path = Path(\"/Users/sharin/Downloads/COS30049/Assignment/Assignment_2/COS30049-Computing-Technology-Innovation-Project-by-YSA\")\n",
        "data_path = base_path / \"data\" / \"singapore\"\n",
        "clean_path = data_path / \"clean\"\n",
        "\n",
        "print(f\"üìÅ Clean data location: {clean_path}\")\n",
        "print(f\"üìÅ Output will be saved to: {data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and Combine Year-by-Year Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pollutants data...\n",
            "  ‚úì Loaded pollutants_2015: 365 records\n",
            "  ‚úì Loaded pollutants_2016: 319 records\n",
            "  ‚úì Loaded pollutants_2017: 361 records\n",
            "  ‚úì Loaded pollutants_2018: 365 records\n",
            "  ‚úì Loaded pollutants_2019: 360 records\n",
            "  ‚úì Loaded pollutants_2020: 362 records\n",
            "  ‚úì Loaded pollutants_2021: 353 records\n",
            "  ‚úì Loaded pollutants_2022: 364 records\n",
            "  ‚úì Loaded pollutants_2023: 346 records\n",
            "  ‚úì Loaded pollutants_2024: 366 records\n",
            "\n",
            "‚úÖ Total pollutants records: 3561\n",
            "   Date range: 2015-01-01 00:00:00 to 2024-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Load all pollutants data (year by year)\n",
        "print(\"Loading pollutants data...\")\n",
        "pollutants_dfs = []\n",
        "for year in range(2015, 2025):\n",
        "    file_path = clean_path / 'pollutants' / f'pollutants_clean_{year}.csv'\n",
        "    if file_path.exists():\n",
        "        df = pd.read_csv(file_path)\n",
        "        pollutants_dfs.append(df)\n",
        "        print(f\"  ‚úì Loaded pollutants_{year}: {len(df)} records\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  File not found: {file_path}\")\n",
        "\n",
        "# Combine all pollutants data\n",
        "if pollutants_dfs:\n",
        "    pollutants_data = pd.concat(pollutants_dfs, ignore_index=True)\n",
        "    pollutants_data['Date'] = pd.to_datetime(pollutants_data['Date'])\n",
        "    print(f\"\\n‚úÖ Total pollutants records: {len(pollutants_data)}\")\n",
        "    print(f\"   Date range: {pollutants_data['Date'].min()} to {pollutants_data['Date'].max()}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No pollutants data found!\")\n",
        "    pollutants_data = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading weather data...\n",
            "  ‚úì Loaded weather_2015: 365 records\n",
            "  ‚úì Loaded weather_2016: 366 records\n",
            "  ‚úì Loaded weather_2017: 365 records\n",
            "  ‚úì Loaded weather_2018: 365 records\n",
            "  ‚úì Loaded weather_2019: 365 records\n",
            "  ‚úì Loaded weather_2020: 366 records\n",
            "  ‚úì Loaded weather_2021: 365 records\n",
            "  ‚úì Loaded weather_2022: 365 records\n",
            "  ‚úì Loaded weather_2023: 365 records\n",
            "  ‚úì Loaded weather_2024: 366 records\n",
            "\n",
            "‚úÖ Total weather records: 3653\n",
            "   Date range: 2015-01-01 00:00:00 to 2024-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Load all weather data (year by year)\n",
        "print(\"\\nLoading weather data...\")\n",
        "weather_dfs = []\n",
        "for year in range(2015, 2025):\n",
        "    file_path = clean_path / 'weather' / f'weather_clean_{year}.csv'\n",
        "    if file_path.exists():\n",
        "        df = pd.read_csv(file_path)\n",
        "        weather_dfs.append(df)\n",
        "        print(f\"  ‚úì Loaded weather_{year}: {len(df)} records\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  File not found: {file_path}\")\n",
        "\n",
        "# Combine all weather data\n",
        "if weather_dfs:\n",
        "    weather_data = pd.concat(weather_dfs, ignore_index=True)\n",
        "    weather_data['Date'] = pd.to_datetime(weather_data['Date'])\n",
        "    print(f\"\\n‚úÖ Total weather records: {len(weather_data)}\")\n",
        "    print(f\"   Date range: {weather_data['Date'].min()} to {weather_data['Date'].max()}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No weather data found!\")\n",
        "    weather_data = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Merge Pollutants and Weather Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MERGING DATA\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Merge completed successfully!\n",
            "   Total merged records: 3561\n",
            "   Date range: 2015-01-01 00:00:00 to 2024-12-31 00:00:00\n",
            "   Columns: ['Country', 'Region', 'Date', 'AQI', 'Temperature', 'RelativeHumidity', 'WindSpeed']\n"
          ]
        }
      ],
      "source": [
        "if pollutants_data is not None and weather_data is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MERGING DATA\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Select only the columns we need from pollutants (Country, Region, Date, AQI)\n",
        "    pollutants_subset = pollutants_data[['Country', 'Region', 'Date', 'AQI']].copy()\n",
        "    \n",
        "    # Select only the columns we need from weather (Date, Temperature, RelativeHumidity, WindSpeed)\n",
        "    weather_subset = weather_data[['Date', 'Temperature', 'RelativeHumidity', 'WindSpeed']].copy()\n",
        "    \n",
        "    # Merge on Date (inner join to keep only matching records)\n",
        "    merged_data = pd.merge(\n",
        "        pollutants_subset,\n",
        "        weather_subset,\n",
        "        on='Date',\n",
        "        how='inner'\n",
        "    )\n",
        "    \n",
        "    # Reorder columns to match final structure: Country | Region | Date | AQI | Temperature | RelativeHumidity | WindSpeed\n",
        "    merged_data = merged_data[['Country', 'Region', 'Date', 'AQI', 'Temperature', 'RelativeHumidity', 'WindSpeed']]\n",
        "    \n",
        "    # Sort by Date\n",
        "    merged_data = merged_data.sort_values('Date').reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Merge completed successfully!\")\n",
        "    print(f\"   Total merged records: {len(merged_data)}\")\n",
        "    print(f\"   Date range: {merged_data['Date'].min()} to {merged_data['Date'].max()}\")\n",
        "    print(f\"   Columns: {list(merged_data.columns)}\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\n‚ùå Cannot merge - missing pollutants or weather data!\")\n",
        "    merged_data = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Data Quality Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "DATA QUALITY CHECK\n",
            "================================================================================\n",
            "\n",
            "Missing values:\n",
            "Country             0\n",
            "Region              0\n",
            "Date                0\n",
            "AQI                 0\n",
            "Temperature         0\n",
            "RelativeHumidity    0\n",
            "WindSpeed           0\n",
            "dtype: int64\n",
            "\n",
            "Data types:\n",
            "Country                     object\n",
            "Region                      object\n",
            "Date                datetime64[ns]\n",
            "AQI                        float64\n",
            "Temperature                float64\n",
            "RelativeHumidity           float64\n",
            "WindSpeed                  float64\n",
            "dtype: object\n",
            "\n",
            "Region distribution:\n",
            "Region\n",
            "Central       715\n",
            "East          715\n",
            "North         709\n",
            "North-East    713\n",
            "West          709\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Statistical summary:\n",
            "               AQI  Temperature  RelativeHumidity    WindSpeed\n",
            "count  3561.000000  3561.000000       3561.000000  3561.000000\n",
            "mean     48.174406    26.575667         85.714302     8.252011\n",
            "std      10.154003     0.880058          4.021479     2.784917\n",
            "min      18.900000    22.530000         63.920000     2.990000\n",
            "25%      41.740000    26.000000         83.470000     6.090000\n",
            "50%      49.610000    26.600000         86.140000     7.780000\n",
            "75%      53.670000    27.200000         88.480000     9.950000\n",
            "max     119.480000    28.940000         97.530000    20.780000\n",
            "\n",
            "Sample data (first 10 rows):\n",
            "     Country      Region       Date    AQI  Temperature  RelativeHumidity  \\\n",
            "0  Singapore        East 2015-01-01  53.46        24.62             88.69   \n",
            "1  Singapore       North 2015-01-02  53.46        25.49             78.11   \n",
            "2  Singapore  North-East 2015-01-03  53.46        25.88             79.30   \n",
            "3  Singapore        West 2015-01-04  53.46        25.80             80.06   \n",
            "4  Singapore     Central 2015-01-05  53.46        26.06             82.75   \n",
            "5  Singapore        East 2015-01-06  53.46        25.51             88.12   \n",
            "6  Singapore       North 2015-01-07  53.46        25.69             86.49   \n",
            "7  Singapore  North-East 2015-01-08  53.46        24.51             90.77   \n",
            "8  Singapore        West 2015-01-09  53.46        23.88             92.62   \n",
            "9  Singapore     Central 2015-01-10  53.46        25.26             87.28   \n",
            "\n",
            "   WindSpeed  \n",
            "0      11.65  \n",
            "1      14.05  \n",
            "2      13.74  \n",
            "3      12.01  \n",
            "4       9.49  \n",
            "5       9.45  \n",
            "6       9.50  \n",
            "7       8.65  \n",
            "8       9.79  \n",
            "9      11.79  \n"
          ]
        }
      ],
      "source": [
        "if merged_data is not None:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"DATA QUALITY CHECK\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Check for missing values\n",
        "    print(\"\\nMissing values:\")\n",
        "    print(merged_data.isnull().sum())\n",
        "    \n",
        "    # Check data types\n",
        "    print(\"\\nData types:\")\n",
        "    print(merged_data.dtypes)\n",
        "    \n",
        "    # Check region distribution\n",
        "    print(\"\\nRegion distribution:\")\n",
        "    print(merged_data['Region'].value_counts().sort_index())\n",
        "    \n",
        "    # Statistical summary\n",
        "    print(\"\\nStatistical summary:\")\n",
        "    print(merged_data[['AQI', 'Temperature', 'RelativeHumidity', 'WindSpeed']].describe())\n",
        "    \n",
        "    # Sample data\n",
        "    print(\"\\nSample data (first 10 rows):\")\n",
        "    print(merged_data.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Save Merged Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MERGE COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Merged data saved to: /Users/sharin/Downloads/COS30049/Assignment/Assignment_2/COS30049-Computing-Technology-Innovation-Project-by-YSA/data/singapore/singapore_merged_2015_2024.csv\n",
            "   Total records: 3561\n",
            "   Columns: ['Country', 'Region', 'Date', 'AQI', 'Temperature', 'RelativeHumidity', 'WindSpeed']\n",
            "   File size: 176.87 KB\n",
            "\n",
            "üìä Final structure: Country | Region | Date | AQI | Temperature | RelativeHumidity | WindSpeed\n",
            "\n",
            "üéâ Data is ready for analysis and modeling!\n"
          ]
        }
      ],
      "source": [
        "if merged_data is not None:\n",
        "    # Save the merged data\n",
        "    output_file = data_path / 'singapore_merged_2015_2024.csv'\n",
        "    merged_data.to_csv(output_file, index=False)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MERGE COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\n‚úÖ Merged data saved to: {output_file}\")\n",
        "    print(f\"   Total records: {len(merged_data)}\")\n",
        "    print(f\"   Columns: {list(merged_data.columns)}\")\n",
        "    print(f\"   File size: {output_file.stat().st_size / 1024:.2f} KB\")\n",
        "    print(f\"\\nüìä Final structure: Country | Region | Date | AQI | Temperature | RelativeHumidity | WindSpeed\")\n",
        "    print(f\"\\nüéâ Data is ready for analysis and modeling!\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Merge failed - no data to save\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook successfully merged cleaned Singapore data (2015-2024) into a single file.\n",
        "\n",
        "### Output File:\n",
        "**`singapore_merged_2015_2024.csv`**\n",
        "- **Location**: `data/singapore/`\n",
        "- **Columns**: Country | Region | Date | AQI | Temperature | RelativeHumidity | WindSpeed\n",
        "- **Records**: ~3,561 daily records\n",
        "- **Date Range**: 2015-01-01 to 2024-12-31\n",
        "- **Regions**: Central, East, North, North-East, West\n",
        "\n",
        "### Data Quality:\n",
        "- ‚úÖ No missing values\n",
        "- ‚úÖ All numeric values rounded to 2 decimal places\n",
        "- ‚úÖ Data sorted by date\n",
        "- ‚úÖ Consistent column names and formats\n",
        "\n",
        "### Next Steps:\n",
        "1. Use this merged file for data analysis\n",
        "2. Create visualizations (AQI trends, correlation plots, etc.)\n",
        "3. Build machine learning models for AQI prediction\n",
        "4. Compare with Thailand data for regional analysis"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
