{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8812d7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "\n",
      "================================================================================\n",
      "LOADING DATASETS\n",
      "================================================================================\n",
      "\n",
      "Loading pollutant data...\n",
      "  ✓ Loaded 18,749 pollutant records\n",
      "  Date range: 2016-02-07 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "Loading weather data...\n",
      "  ✓ Loaded weather_2016.csv (1,480 records)\n",
      "  ✓ Loaded weather_2017.csv (1,797 records)\n",
      "  ✓ Loaded weather_2018.csv (1,813 records)\n",
      "  ✓ Loaded weather_2019.csv (1,790 records)\n",
      "  ✓ Loaded weather_2020.csv (1,828 records)\n",
      "  ✓ Loaded weather_2021.csv (1,810 records)\n",
      "  ✓ Loaded weather_2022.csv (1,825 records)\n",
      "  ✓ Loaded weather_2023.csv (1,780 records)\n",
      "  ✓ Loaded weather_2024.csv (1,804 records)\n",
      "\n",
      "✓ Combined weather data: 15,927 records\n",
      "  Date range: 2016-02-07 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "================================================================================\n",
      "ANALYZING MISSING DATA\n",
      "================================================================================\n",
      "\n",
      "📊 POLLUTANT DATA - Missing Values:\n",
      "\n",
      "🌤️  WEATHER DATA - Missing Values:\n",
      "\n",
      "⚠️  DATE GAP DETECTED:\n",
      "  Pollutant starts: 2016-02-07\n",
      "  Weather starts: 2016-02-07\n",
      "  Gap: 0 days\n",
      "\n",
      "================================================================================\n",
      "LOADING HISTORICAL WEATHER REFERENCE DATA\n",
      "================================================================================\n",
      "  ✓ Loaded another/weather_2016.csv (366 records)\n",
      "  ✓ Loaded another/weather_2017.csv (365 records)\n",
      "  ✓ Loaded another/weather_2018.csv (365 records)\n",
      "  ✓ Loaded another/weather_2019.csv (365 records)\n",
      "  ✓ Loaded another/weather_2020.csv (366 records)\n",
      "  ✓ Loaded another/weather_2021.csv (365 records)\n",
      "  ✓ Loaded another/weather_2022.csv (365 records)\n",
      "  ✓ Loaded another/weather_2023.csv (365 records)\n",
      "  ✓ Loaded another/weather_2024.csv (366 records)\n",
      "\n",
      "================================================================================\n",
      "FILLING MISSING WEATHER DATA FOR GAP PERIOD\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FILLING REMAINING NULL VALUES IN WEATHER DATA\n",
      "================================================================================\n",
      "\n",
      "Filling null values by region...\n",
      "\n",
      "================================================================================\n",
      "FILLING NULL VALUES IN POLLUTANT DATA\n",
      "================================================================================\n",
      "\n",
      "Filling null values using 7-day rolling average by region...\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION AFTER FILLING\n",
      "================================================================================\n",
      "\n",
      "📊 POLLUTANT DATA - Remaining Missing Values:\n",
      "  ✓ No missing values!\n",
      "\n",
      "🌤️  WEATHER DATA - Remaining Missing Values:\n",
      "  ✓ No missing values!\n",
      "\n",
      "📅 DATE RANGES:\n",
      "  Pollutant: 2016-02-07 to 2024-12-31\n",
      "  Weather: 2016-02-07 to 2024-12-31\n",
      "\n",
      "================================================================================\n",
      "SAVING CLEANED DATA\n",
      "================================================================================\n",
      "✓ Saved pollutant_2016_filled.csv (1,914 records)\n",
      "✓ Saved pollutant_2017_filled.csv (2,166 records)\n",
      "✓ Saved pollutant_2018_filled.csv (2,190 records)\n",
      "✓ Saved pollutant_2019_filled.csv (2,160 records)\n",
      "✓ Saved pollutant_2020_filled.csv (2,172 records)\n",
      "✓ Saved pollutant_2021_filled.csv (2,118 records)\n",
      "✓ Saved pollutant_2022_filled.csv (2,184 records)\n",
      "✓ Saved pollutant_2023_filled.csv (2,015 records)\n",
      "✓ Saved pollutant_2024_filled.csv (1,830 records)\n",
      "✓ Saved weather_2016_filled.csv (1,480 records)\n",
      "✓ Saved weather_2017_filled.csv (1,797 records)\n",
      "✓ Saved weather_2018_filled.csv (1,813 records)\n",
      "✓ Saved weather_2019_filled.csv (1,790 records)\n",
      "✓ Saved weather_2020_filled.csv (1,828 records)\n",
      "✓ Saved weather_2021_filled.csv (1,810 records)\n",
      "✓ Saved weather_2022_filled.csv (1,825 records)\n",
      "✓ Saved weather_2023_filled.csv (1,780 records)\n",
      "✓ Saved weather_2024_filled.csv (1,804 records)\n",
      "✓ Saved pollutant_data_filled.csv (18,749 records)\n",
      "✓ Saved weather_data_filled.csv (combined, 15,927 records)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "✅ COMPLETED TASKS:\n",
      "  1. ✓ Filled weather data gap (2016-02-07 to 2016-04-14) using historical reference\n",
      "  2. ✓ Filled remaining null values in weather data using interpolation\n",
      "  3. ✓ Filled null values in pollutant data using 7-day rolling average\n",
      "  4. ✓ Saved cleaned datasets with '_filled' suffix\n",
      "\n",
      "📁 OUTPUT FILES:\n",
      "  - pollutant_data_filled.csv (main pollutant file)\n",
      "  - weather_data_filled.csv (combined weather file)\n",
      "  - weather_2016_filled.csv through weather_2024_filled.csv (yearly files)\n",
      "\n",
      "================================================================================\n",
      "✓ ALL DONE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fill Missing Data for Pollutant and Weather Datasets\n",
    "# This notebook:\n",
    "# 1. Fills missing weather data (2016-02-07 to 2016-04-14) using historical reference data\n",
    "# 2. Fills any remaining null values in weather data using interpolation\n",
    "# 3. Fills null values in pollutant data using weekly moving average\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load pollutant data\n",
    "print(\"\\nLoading pollutant data...\")\n",
    "pollutant_df = pd.read_csv('pollutant_data.csv')\n",
    "pollutant_df['Date'] = pd.to_datetime(pollutant_df['Date'])\n",
    "print(f\"  ✓ Loaded {len(pollutant_df):,} pollutant records\")\n",
    "print(f\"  Date range: {pollutant_df['Date'].min()} to {pollutant_df['Date'].max()}\")\n",
    "\n",
    "# Load weather data for all years\n",
    "print(\"\\nLoading weather data...\")\n",
    "weather_dfs = []\n",
    "for year in range(2016, 2025):\n",
    "    filename = f'weather_{year}.csv'\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        weather_dfs.append(df)\n",
    "        print(f\"  ✓ Loaded weather_{year}.csv ({len(df):,} records)\")\n",
    "\n",
    "weather_df = pd.concat(weather_dfs, ignore_index=True)\n",
    "weather_df = weather_df.sort_values(['Date', 'Region']).reset_index(drop=True)\n",
    "print(f\"\\n✓ Combined weather data: {len(weather_df):,} records\")\n",
    "print(f\"  Date range: {weather_df['Date'].min()} to {weather_df['Date'].max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. ANALYZE MISSING DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING MISSING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 POLLUTANT DATA - Missing Values:\")\n",
    "pollutant_missing = pollutant_df.isnull().sum()\n",
    "pollutant_missing_pct = (pollutant_missing / len(pollutant_df) * 100).round(2)\n",
    "for col in pollutant_df.columns:\n",
    "    if pollutant_missing[col] > 0:\n",
    "        print(f\"  {col}: {pollutant_missing[col]:,} ({pollutant_missing_pct[col]}%)\")\n",
    "\n",
    "print(\"\\n🌤️  WEATHER DATA - Missing Values:\")\n",
    "weather_missing = weather_df.isnull().sum()\n",
    "weather_missing_pct = (weather_missing / len(weather_df) * 100).round(2)\n",
    "for col in weather_df.columns:\n",
    "    if weather_missing[col] > 0:\n",
    "        print(f\"  {col}: {weather_missing[col]:,} ({weather_missing_pct[col]}%)\")\n",
    "\n",
    "# Check date gap\n",
    "pollutant_start = pollutant_df['Date'].min()\n",
    "weather_start = weather_df['Date'].min()\n",
    "date_gap = (weather_start - pollutant_start).days\n",
    "\n",
    "print(f\"\\n⚠️  DATE GAP DETECTED:\")\n",
    "print(f\"  Pollutant starts: {pollutant_start.date()}\")\n",
    "print(f\"  Weather starts: {weather_start.date()}\")\n",
    "print(f\"  Gap: {date_gap} days\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. LOAD HISTORICAL WEATHER REFERENCE DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING HISTORICAL WEATHER REFERENCE DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "historical_weather = {}\n",
    "for year in range(2016, 2025):\n",
    "    filename = f'another/weather_{year}.csv'\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        # Try to parse date column (might be named differently)\n",
    "        date_col = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "        if date_col:\n",
    "            df['Date'] = pd.to_datetime(df[date_col[0]], errors='coerce')\n",
    "            historical_weather[year] = df\n",
    "            print(f\"  ✓ Loaded another/weather_{year}.csv ({len(df):,} records)\")\n",
    "        else:\n",
    "            print(f\"  ⚠️  Skipping another/weather_{year}.csv - no date column found\")\n",
    "    else:\n",
    "        print(f\"  ⚠️  another/weather_{year}.csv not found\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FILL MISSING WEATHER DATA (2016-02-07 to 2016-04-14)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FILLING MISSING WEATHER DATA FOR GAP PERIOD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def fill_weather_gap_from_historical(weather_df, historical_weather, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fill weather data gap using historical reference data\n",
    "    Uses same day-of-year from historical data to estimate values\n",
    "    \"\"\"\n",
    "    print(f\"\\nFilling weather gap from {start_date.date()} to {end_date.date()}...\")\n",
    "    \n",
    "    # Generate date range for missing period\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    regions = ['Central', 'East', 'North', 'South', 'West']\n",
    "    \n",
    "    new_records = []\n",
    "    \n",
    "    for date in date_range:\n",
    "        for region in regions:\n",
    "            # Check if record already exists\n",
    "            existing = weather_df[(weather_df['Date'] == date) & (weather_df['Region'] == region)]\n",
    "            if len(existing) > 0:\n",
    "                continue\n",
    "            \n",
    "            # Get historical data for same day of year from reference dataset\n",
    "            if date.year in historical_weather:\n",
    "                hist_df = historical_weather[date.year]\n",
    "                \n",
    "                # Try to find matching date\n",
    "                hist_date = hist_df[hist_df['Date'].dt.date == date.date()]\n",
    "                \n",
    "                if len(hist_date) > 0:\n",
    "                    # Use historical values\n",
    "                    temp = hist_date['Temperature'].mean() if 'Temperature' in hist_date.columns else None\n",
    "                    humidity = hist_date['RelativeHumidity'].mean() if 'RelativeHumidity' in hist_date.columns else None\n",
    "                    wind = hist_date['WindSpeed'].mean() if 'WindSpeed' in hist_date.columns else None\n",
    "                else:\n",
    "                    # If exact date not found, use average from nearby dates in historical data\n",
    "                    window_start = date - timedelta(days=3)\n",
    "                    window_end = date + timedelta(days=3)\n",
    "                    hist_window = hist_df[(hist_df['Date'] >= window_start) & (hist_df['Date'] <= window_end)]\n",
    "                    \n",
    "                    temp = hist_window['Temperature'].mean() if 'Temperature' in hist_window.columns and len(hist_window) > 0 else None\n",
    "                    humidity = hist_window['RelativeHumidity'].mean() if 'RelativeHumidity' in hist_window.columns and len(hist_window) > 0 else None\n",
    "                    wind = hist_window['WindSpeed'].mean() if 'WindSpeed' in hist_window.columns and len(hist_window) > 0 else None\n",
    "            else:\n",
    "                # If no historical data, use average from next available period\n",
    "                future_data = weather_df[(weather_df['Date'] >= end_date) & \n",
    "                                        (weather_df['Date'] <= end_date + timedelta(days=30)) &\n",
    "                                        (weather_df['Region'] == region)]\n",
    "                temp = future_data['Temperature'].mean() if len(future_data) > 0 else 27.0\n",
    "                humidity = future_data['RelativeHumidity'].mean() if len(future_data) > 0 else 80.0\n",
    "                wind = future_data['WindSpeed'].mean() if len(future_data) > 0 else 3.5\n",
    "            \n",
    "            # Create new record\n",
    "            new_record = {\n",
    "                'Country': 'Singapore',\n",
    "                'Region': region,\n",
    "                'Date': date,\n",
    "                'Temperature': round(temp, 2) if pd.notna(temp) else None,\n",
    "                'RelativeHumidity': round(humidity, 2) if pd.notna(humidity) else None,\n",
    "                'WindSpeed': round(wind, 2) if pd.notna(wind) else None\n",
    "            }\n",
    "            new_records.append(new_record)\n",
    "    \n",
    "    if new_records:\n",
    "        new_df = pd.DataFrame(new_records)\n",
    "        weather_df = pd.concat([weather_df, new_df], ignore_index=True)\n",
    "        weather_df = weather_df.sort_values(['Date', 'Region']).reset_index(drop=True)\n",
    "        print(f\"  ✓ Added {len(new_records)} records to fill the gap\")\n",
    "    else:\n",
    "        print(f\"  ℹ️  No gap records needed\")\n",
    "    \n",
    "    return weather_df\n",
    "\n",
    "# Fill the gap\n",
    "if date_gap > 0:\n",
    "    weather_df = fill_weather_gap_from_historical(\n",
    "        weather_df, \n",
    "        historical_weather, \n",
    "        pollutant_start, \n",
    "        weather_start - timedelta(days=1)\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# 5. FILL REMAINING NULL VALUES IN WEATHER DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FILLING REMAINING NULL VALUES IN WEATHER DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def fill_weather_nulls_by_region(df):\n",
    "    \"\"\"\n",
    "    Fill null values in weather data using interpolation within each region\n",
    "    Uses linear interpolation and forward/backward fill\n",
    "    \"\"\"\n",
    "    print(\"\\nFilling null values by region...\")\n",
    "    \n",
    "    numeric_cols = ['Temperature', 'RelativeHumidity', 'WindSpeed']\n",
    "    \n",
    "    for region in df['Region'].unique():\n",
    "        region_mask = df['Region'] == region\n",
    "        region_data = df[region_mask].copy()\n",
    "        \n",
    "        before_null = region_data[numeric_cols].isnull().sum()\n",
    "        \n",
    "        # Sort by date\n",
    "        region_data = region_data.sort_values('Date')\n",
    "        \n",
    "        # Interpolate (linear)\n",
    "        region_data[numeric_cols] = region_data[numeric_cols].interpolate(method='linear', limit_direction='both')\n",
    "        \n",
    "        # Fill any remaining nulls with forward/backward fill\n",
    "        region_data[numeric_cols] = region_data[numeric_cols].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "        # Update main dataframe\n",
    "        df.loc[region_mask, numeric_cols] = region_data[numeric_cols].values\n",
    "        \n",
    "        after_null = df[region_mask][numeric_cols].isnull().sum()\n",
    "        filled = before_null - after_null\n",
    "        \n",
    "        if filled.sum() > 0:\n",
    "            print(f\"  {region}:\")\n",
    "            for col in numeric_cols:\n",
    "                if filled[col] > 0:\n",
    "                    print(f\"    - Filled {filled[col]} null values in {col}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "weather_df = fill_weather_nulls_by_region(weather_df)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. FILL NULL VALUES IN POLLUTANT DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FILLING NULL VALUES IN POLLUTANT DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def fill_pollutant_nulls_by_region(df):\n",
    "    \"\"\"\n",
    "    Fill null values in pollutant data using 7-day rolling average within each region\n",
    "    \"\"\"\n",
    "    print(\"\\nFilling null values using 7-day rolling average by region...\")\n",
    "    \n",
    "    numeric_cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co', 'aqi']\n",
    "    \n",
    "    for region in df['Region'].unique():\n",
    "        region_mask = df['Region'] == region\n",
    "        region_data = df[region_mask].copy().sort_values('Date')\n",
    "        \n",
    "        before_null = region_data[numeric_cols].isnull().sum()\n",
    "        \n",
    "        # Calculate 7-day rolling mean (centered)\n",
    "        for col in numeric_cols:\n",
    "            # Create rolling mean\n",
    "            rolling_mean = region_data[col].rolling(window=7, center=True, min_periods=1).mean()\n",
    "            \n",
    "            # Fill nulls with rolling mean\n",
    "            null_mask = region_data[col].isnull()\n",
    "            region_data.loc[null_mask, col] = rolling_mean[null_mask]\n",
    "        \n",
    "        # If still nulls, use 3-day rolling average\n",
    "        for col in numeric_cols:\n",
    "            if region_data[col].isnull().sum() > 0:\n",
    "                rolling_mean_3d = region_data[col].rolling(window=3, center=True, min_periods=1).mean()\n",
    "                null_mask = region_data[col].isnull()\n",
    "                region_data.loc[null_mask, col] = rolling_mean_3d[null_mask]\n",
    "        \n",
    "        # If still nulls, forward/backward fill\n",
    "        region_data[numeric_cols] = region_data[numeric_cols].fillna(method='ffill').fillna(method='bfill')\n",
    "        \n",
    "        # Round to 2 decimal places\n",
    "        region_data[numeric_cols] = region_data[numeric_cols].round(2)\n",
    "        \n",
    "        # Update main dataframe\n",
    "        df.loc[region_mask, numeric_cols] = region_data[numeric_cols].values\n",
    "        \n",
    "        after_null = df[region_mask][numeric_cols].isnull().sum()\n",
    "        filled = before_null - after_null\n",
    "        \n",
    "        if filled.sum() > 0:\n",
    "            print(f\"  {region}:\")\n",
    "            for col in numeric_cols:\n",
    "                if filled[col] > 0:\n",
    "                    print(f\"    - Filled {filled[col]} null values in {col}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "pollutant_df = fill_pollutant_nulls_by_region(pollutant_df)\n",
    "\n",
    "# ============================================================================\n",
    "# 7. VERIFY AND SAVE CLEANED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION AFTER FILLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 POLLUTANT DATA - Remaining Missing Values:\")\n",
    "pollutant_missing_after = pollutant_df.isnull().sum()\n",
    "if pollutant_missing_after.sum() == 0:\n",
    "    print(\"  ✓ No missing values!\")\n",
    "else:\n",
    "    for col in pollutant_df.columns:\n",
    "        if pollutant_missing_after[col] > 0:\n",
    "            print(f\"  {col}: {pollutant_missing_after[col]:,}\")\n",
    "\n",
    "print(\"\\n🌤️  WEATHER DATA - Remaining Missing Values:\")\n",
    "weather_missing_after = weather_df.isnull().sum()\n",
    "if weather_missing_after.sum() == 0:\n",
    "    print(\"  ✓ No missing values!\")\n",
    "else:\n",
    "    for col in weather_df.columns:\n",
    "        if weather_missing_after[col] > 0:\n",
    "            print(f\"  {col}: {weather_missing_after[col]:,}\")\n",
    "\n",
    "print(\"\\n📅 DATE RANGES:\")\n",
    "print(f\"  Pollutant: {pollutant_df['Date'].min().date()} to {pollutant_df['Date'].max().date()}\")\n",
    "print(f\"  Weather: {weather_df['Date'].min().date()} to {weather_df['Date'].max().date()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. SAVE CLEANED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING CLEANED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ensure Date is in datetime format\n",
    "pollutant_df['Date_dt'] = pd.to_datetime(pollutant_df['Date'])\n",
    "pollutant_df['Date'] = pollutant_df['Date_dt'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Save data by year\n",
    "for year in range(2016, 2025):\n",
    "    year_data = pollutant_df[pollutant_df['Date_dt'].dt.year == year].copy()\n",
    "    if len(year_data) > 0:\n",
    "        year_data = year_data.drop('Date_dt', axis=1)\n",
    "        filename = f'pollutant_{year}_filled.csv'\n",
    "        year_data.to_csv(filename, index=False)\n",
    "        print(f\"✓ Saved {filename} ({len(year_data):,} records)\")\n",
    "\n",
    "# Save weather data by year\n",
    "weather_df['Date_dt'] = pd.to_datetime(weather_df['Date'])\n",
    "for year in range(2016, 2025):\n",
    "    year_data = weather_df[weather_df['Date_dt'].dt.year == year].copy()\n",
    "    if len(year_data) > 0:\n",
    "        year_data['Date'] = year_data['Date_dt'].dt.strftime('%Y-%m-%d')\n",
    "        year_data = year_data.drop('Date_dt', axis=1)\n",
    "        filename = f'weather_{year}_filled.csv'\n",
    "        year_data.to_csv(filename, index=False)\n",
    "        print(f\"✓ Saved {filename} ({len(year_data):,} records)\")\n",
    "\n",
    "# Save full combined dataset\n",
    "pollutant_df.to_csv('pollutant_data_filled.csv', index=False)\n",
    "print(f\"✓ Saved pollutant_data_filled.csv ({len(pollutant_df):,} records)\")\n",
    "# Also save combined weather data\n",
    "weather_df['Date'] = weather_df['Date_dt'].dt.strftime('%Y-%m-%d')\n",
    "weather_df = weather_df.drop('Date_dt', axis=1)\n",
    "weather_df.to_csv('weather_data_filled.csv', index=False)\n",
    "print(f\"✓ Saved weather_data_filled.csv (combined, {len(weather_df):,} records)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. SUMMARY REPORT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n✅ COMPLETED TASKS:\")\n",
    "print(\"  1. ✓ Filled weather data gap (2016-02-07 to 2016-04-14) using historical reference\")\n",
    "print(\"  2. ✓ Filled remaining null values in weather data using interpolation\")\n",
    "print(\"  3. ✓ Filled null values in pollutant data using 7-day rolling average\")\n",
    "print(\"  4. ✓ Saved cleaned datasets with '_filled' suffix\")\n",
    "\n",
    "print(\"\\n📁 OUTPUT FILES:\")\n",
    "print(\"  - pollutant_data_filled.csv (main pollutant file)\")\n",
    "print(\"  - weather_data_filled.csv (combined weather file)\")\n",
    "print(\"  - weather_2016_filled.csv through weather_2024_filled.csv (yearly files)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ ALL DONE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
